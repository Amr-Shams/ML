in the context of the data, we represent each feature of the data as a dimension to our problem, and as you guess the more dimensions the more the difficulty to solve the problem. 
but we have two main methods
1. **Feature Selection:** to extract out of the context the relevant features only. 
2. **Feature Aggregation:**  to combine one or two features together in one dimension.
	-     **PCA**: A linear unsupervised ML algorithm
	    
	-   **Linear discriminant analysis** (**LDA**): A linear supervised ML algorithm
	    
	-   **Kernel principal component analysis**: A nonlinear algorithm
- ### PCA
	the method is used as a linear method 
	 with a full explanation  [PCA](https://www.youtube.com/watch?v=FgakZw6K1QQ) 
	The following are the limitations of PCA:
	-   PCA can only be used for continuous variables and is not relevant for category variables.
    
	-   While aggregating, PCA approximates the component variables; it simplifies the problem of dimensionality at the expense of accuracy. This trade-off should be carefully studied before using PCA.
	